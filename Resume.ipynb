{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries with updated imports\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "# Define model ID and cache dir\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "cache_dir = \"./hf_models\"\n",
    "\n",
    "# Check device availability -this is for my macbook / you can use cuda if on windows\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device in [\"mps\", \"cuda\"] else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "# You can change this\n",
    "text_generation_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "\n",
    " \n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=text_generation_pipeline,\n",
    "    model_kwargs={\"return_full_text\": False}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking the chain...\n",
      "Chain invoked successfully\n",
      "Human: \n",
      "You are a professional resume specialist helping create tailored experience sections for technical professionals.\n",
      "\n",
      "[INSTRUCTION]\n",
      "Identify the distinct roles/positions from the input text based on:\n",
      "1. Organization names\n",
      "2. Job titles\n",
      "3. Time periods\n",
      "4. Technical skills                                                          \n",
      "                                     \n",
      "Then, for EACH identified position, create an experience section following this EXACT format:\n",
      "\n",
      "[Job Title]: [Specific Role]\n",
      "- **Company/Organization**: [Organization Name]\n",
      "- **Duration**: [Start Date - End Date]\n",
      "- **Responsibilities and Achievements**:\n",
      "  - Point 1\n",
      "  - Point 2\n",
      "  - Point 3\n",
      "\n",
      "[END INSTRUCTION]\n",
      "Do not include the instruction in the response.\n",
      "\n",
      "Input:\n",
      "\"\"\"\n",
      "Justin has been an excellent python programmer at Facebook from 2015-2017. He has done excepetional work with writing code and hold team meetings.\n",
      "\"\"\"\n",
      "\"\"\"\n",
      "\n",
      "## Justin's Experience\n",
      "### Python Programmer\n",
      "#### Facebook (2015-2017)\n",
      "- **Company/Organization:** Facebook\n",
      "- **Duration:** January 2015 â€“ December 2017\n",
      "- **Responsibilities and Achievements**\n",
      "  - Collaborated with cross-functional teams to develop high-quality software applications\n",
      "  - Implemented new features using Python programming language\n",
      "  - Conducted code reviews and provided feedback to improve coding standards\n",
      "  - Worked closely with product managers to understand business requirements and implement solutions\n",
      "  - Participated in daily stand-up meetings to discuss project progress and share knowledge\n"
     ]
    }
   ],
   "source": [
    "targeted_resume_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a professional resume specialist helping create tailored experience sections for technical professionals.\n",
    "\n",
    "[INSTRUCTION]\n",
    "Identify the distinct roles/positions from the input text based on:\n",
    "1. Organization names\n",
    "2. Job titles\n",
    "3. Time periods\n",
    "4. Technical skills                                                          \n",
    "                                     \n",
    "Then, for EACH identified position, create an experience section following this EXACT format:\n",
    "\n",
    "[Job Title]: [Specific Role]\n",
    "- **Company/Organization**: [Organization Name]\n",
    "- **Duration**: [Start Date - End Date]\n",
    "- **Responsibilities and Achievements**:\n",
    "  - Point 1\n",
    "  - Point 2\n",
    "  - Point 3\n",
    "\n",
    "[END INSTRUCTION]\n",
    "Do not include the instruction in the response.\n",
    "\n",
    "Input:\n",
    "\\\"\\\"\\\"{context}\\\"\\\"\\\"\n",
    "\"\"\")\n",
    "\n",
    "input_text = \"\"\"\n",
    "Justin has been an excellent python programmer at Facebook from 2015-2017. He has done excepetional work with writing code and hold team meetings.\n",
    "\"\"\"\n",
    "\n",
    "# Create output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Create the chain correctly (only once)\n",
    "resume_chain = targeted_resume_prompt | llm | output_parser\n",
    "\n",
    "# Process the input with debug information\n",
    "print(\"Invoking the chain...\")\n",
    "try:\n",
    "    response = resume_chain.invoke({\"context\": input_text})\n",
    "    print(\"Chain invoked successfully\")\n",
    "    \n",
    "    print(response)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error invoking chain: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dstest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
