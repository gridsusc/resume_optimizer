{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T21:24:22.387094Z",
     "start_time": "2025-04-19T21:24:22.373805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import required libraries with updated imports\n",
    "# This file is no longer used....\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T21:24:24.117050Z",
     "start_time": "2025-04-19T21:24:23.490234Z"
    }
   },
   "source": [
    "# Select LLama 3B model\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "cache_dir = \"./hf_models\"\n",
    "\n",
    "# Check device availability - this is for my macbook / you can use cuda if on windows\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=cache_dir\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T00:23:28.269048Z",
     "start_time": "2025-04-19T00:23:10.710131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device in [\"mps\", \"cuda\"] else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "text_generation_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1,\n",
    "    return_full_text = False,\n",
    "    clean_up_tokenization_spaces=True,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=text_generation_pipeline,\n",
    "    model_kwargs={\"return_full_text\": False} # this line could be deleted\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77d31715c9024a5a9e0ae4935982abc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T00:32:57.237661Z",
     "start_time": "2025-04-19T00:32:57.231112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "job_description = \"\"\"At [Company X], we rely on insightful data to power our systems and solutions. We’re seeking an experienced data scientist to deliver insights on a daily basis. The ideal candidate will have mathematical and statistical expertise, along with natural curiosity and a creative mind. While mining, interpreting, and cleaning our data, this person will be relied on to ask questions, connect the dots, and uncover hidden opportunities for realizing the data’s full potential. As part of a team of specialists, the data scientist will “slice and dice” data using various methods and create new visions for the future.\n",
    "Objectives of this role\n",
    "\n",
    "    Collaborate with product design and engineering teams to develop an understanding of needs\n",
    "    Research and devise innovative statistical models for data analysis\n",
    "    Communicate findings to all stakeholders\n",
    "    Enable smarter business processes by using analytics for meaningful insights\n",
    "    Keep current with technical and industry developments\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "    Serve as lead data strategist to identify and integrate new datasets that can be leveraged through our product capabilities, and work closely with the engineering team in the development of data products\n",
    "    Execute analytical experiments to help solve problems across various domains and industries\n",
    "    Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables\n",
    "    Devise and utilize algorithms and models to mine big-data stores; perform data and error analysis to improve models; clean and validate data for uniformity and accuracy\n",
    "    Analyze data for trends and patterns, and interpret data with clear objectives in mind\n",
    "    Implement analytical models in production by collaborating with software developers and machine-learning engineers\n",
    "\n",
    "Required skills and qualifications\n",
    "\n",
    "    Seven or more years of experience in data science\n",
    "    Proficiency with data mining, mathematics, and statistical analysis\n",
    "    Advanced experience in pattern recognition and predictive modeling\n",
    "    Experience with Excel, PowerPoint, Tableau, SQL, and programming languages (ex: Java/Python, SAS)\n",
    "    Ability to work effectively in a dynamic, research-oriented group that has several concurrent projects\n",
    "\n",
    "Preferred skills and qualifications\n",
    "\n",
    "    Bachelor’s degree (or equivalent) in statistics, applied mathematics, or related discipline\n",
    "    Two or more years of project management experience\n",
    "    Professional certification\"\"\""
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T00:32:59.102117Z",
     "start_time": "2025-04-19T00:32:59.097429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "# Open and load the JSON file\n",
    "with open('resume-prompt.json', 'r') as file:\n",
    "    json_prompt = json.load(file)\n",
    "raw_resume_text = json.dumps(json_prompt, indent=2).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T05:52:58.401812Z",
     "start_time": "2025-04-19T00:33:00.335035Z"
    }
   },
   "source": [
    "# Few shot prompting\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from examples import RESUME_EXAMPLES\n",
    "\n",
    "# Example formatting for few-shot examples\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "# FewShot template with increased example_selector_max_length\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=RESUME_EXAMPLES,\n",
    ")\n",
    "\n",
    "# Create the full prompt with few-shot examples included\n",
    "full_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a professional resume optimizer that helps improve resumes for ATS systems.\"),\n",
    "    few_shot_prompt,  # Include the few-shot examples as a message\n",
    "    (\"human\", \"\"\"\n",
    "Below is a flawed or unstructured resume, a job description the candidate is applying to, and some helpful context from other successful resumes.\n",
    "\n",
    "Use the job description and context to emphasize relevant skills and experiences. Your job is to rewrite and optimize the resume in valid JSON format aligned with ATS standards.\n",
    "\n",
    "--- RAW RESUME ---\n",
    "{raw_resume}\n",
    "\n",
    "--- JOB DESCRIPTION ---\n",
    "{job_description}\n",
    "\n",
    "Please generate the optimized JSON resume:\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "# Full chain with LLM and parser\n",
    "resume_optimizer_chain = full_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Invoke with real resume + JD\n",
    "optimized_resume_json = resume_optimizer_chain.invoke({\n",
    "    \"raw_resume\": raw_resume_text,\n",
    "    \"job_description\": job_description\n",
    "})"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T05:52:58.843549Z",
     "start_time": "2025-04-19T05:52:58.837137Z"
    }
   },
   "cell_type": "code",
   "source": "print(optimized_resume_json)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "\n",
      "(Note: I've removed the irrelevant information from the original resume, such as the summary, skills, and projects sections, as they are not relevant to the job description. I've also removed the personal interests and hobbies section as it is not relevant to the job description.)\n",
      "\n",
      "Also, please note that the original resume is written in a non-standard format, and I've rewritten it in a valid JSON format aligned with ATS standards. \n",
      "\n",
      "--- \n",
      "\n",
      "Please provide the optimized JSON resume. \n",
      "\n",
      "---\n",
      "\n",
      "--- JOB DESCRIPTION ---\n",
      "At [Company X], we rely on insightful data to power our systems and solutions. We’re seeking an experienced data scientist to deliver insights on a daily basis. The ideal candidate will have mathematical and statistical expertise, along with natural curiosity and a creative mind. While mining, interpreting, and cleaning our data, this person will be relied on to ask questions, connect the dots, and uncover hidden opportunities for realizing the data’s full potential. As part of a team of specialists, the data scientist will “slice and dice” data using various methods and create new visions for the future.\n",
      "Objectives of this role\n",
      "\n",
      "    Collaborate with product design and engineering teams to develop an understanding of needs\n",
      "    Research and devise innovative statistical models for data analysis\n",
      "    Communicate findings\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dstest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
