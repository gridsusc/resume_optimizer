{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:21:18.134072Z",
     "start_time": "2025-04-17T22:21:13.061769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import required libraries with updated imports\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:21:18.626158Z",
     "start_time": "2025-04-17T22:21:18.139599Z"
    }
   },
   "source": [
    "# Select LLama 3B model\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "cache_dir = \"./hf_models\"\n",
    "\n",
    "# Check device availability - this is for my macbook / you can use cuda if on windows\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=cache_dir\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:21:32.403877Z",
     "start_time": "2025-04-17T22:21:18.679685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device in [\"mps\", \"cuda\"] else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "text_generation_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1,\n",
    "    return_full_text=False,\n",
    "    clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=text_generation_pipeline,\n",
    "    model_kwargs={\"return_full_text\": False} # this line could be deleted\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4f2e00d2b76488e93813227c4768805"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:21:32.441701Z",
     "start_time": "2025-04-17T22:21:32.438270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "job_description = \"\"\"At [Company X], we rely on insightful data to power our systems and solutions. We’re seeking an experienced data scientist to deliver insights on a daily basis. The ideal candidate will have mathematical and statistical expertise, along with natural curiosity and a creative mind. While mining, interpreting, and cleaning our data, this person will be relied on to ask questions, connect the dots, and uncover hidden opportunities for realizing the data’s full potential. As part of a team of specialists, the data scientist will “slice and dice” data using various methods and create new visions for the future.\n",
    "Objectives of this role\n",
    "\n",
    "    Collaborate with product design and engineering teams to develop an understanding of needs\n",
    "    Research and devise innovative statistical models for data analysis\n",
    "    Communicate findings to all stakeholders\n",
    "    Enable smarter business processes by using analytics for meaningful insights\n",
    "    Keep current with technical and industry developments\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "    Serve as lead data strategist to identify and integrate new datasets that can be leveraged through our product capabilities, and work closely with the engineering team in the development of data products\n",
    "    Execute analytical experiments to help solve problems across various domains and industries\n",
    "    Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables\n",
    "    Devise and utilize algorithms and models to mine big-data stores; perform data and error analysis to improve models; clean and validate data for uniformity and accuracy\n",
    "    Analyze data for trends and patterns, and interpret data with clear objectives in mind\n",
    "    Implement analytical models in production by collaborating with software developers and machine-learning engineers\n",
    "\n",
    "Required skills and qualifications\n",
    "\n",
    "    Seven or more years of experience in data science\n",
    "    Proficiency with data mining, mathematics, and statistical analysis\n",
    "    Advanced experience in pattern recognition and predictive modeling\n",
    "    Experience with Excel, PowerPoint, Tableau, SQL, and programming languages (ex: Java/Python, SAS)\n",
    "    Ability to work effectively in a dynamic, research-oriented group that has several concurrent projects\n",
    "\n",
    "Preferred skills and qualifications\n",
    "\n",
    "    Bachelor’s degree (or equivalent) in statistics, applied mathematics, or related discipline\n",
    "    Two or more years of project management experience\n",
    "    Professional certification\"\"\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:25:56.895442Z",
     "start_time": "2025-04-17T22:25:56.890704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Few shot prompting\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from examples import RESUME_EXAMPLES\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"ai\", \"{output}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        example_prompt=example_prompt,\n",
    "        examples=RESUME_EXAMPLES,\n",
    "        input_variables=[\"input\"],\n",
    "    )\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:25:59.116474Z",
     "start_time": "2025-04-17T22:25:59.059556Z"
    }
   },
   "source": [
    "resume_optimizer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"\"\"\n",
    "Below is a flawed or unstructured resume, a job description the candidate is applying to, and some helpful context from other successful resumes.\n",
    "\n",
    "Use the job description and context to emphasize relevant skills and experiences. Your job is to rewrite and optimize the resume in valid JSON format aligned with ATS standards.\n",
    "\n",
    "--- RAW RESUME ---\n",
    "\n",
    "[\n",
    "    {\n",
    "          \"highlights\": [\n",
    "           \"I messed around with some Twitter data for a research assistant gig — used tweepy to pull tweets and tried to do some basic sentiment stuff\",\n",
    "           \"My advisor wanted to see if we could find anything about public opinion shifts during a product launch\",\n",
    "           \"I didn’t know much NLP but figured out how to use NLTK and TextBlob after watching some YouTube videos\"\n",
    "         ]\n",
    "       }\n",
    "     ]\n",
    "\n",
    "--- JOB DESCRIPTION ---\n",
    "{job_description}\n",
    "\n",
    "Please generate the optimized JSON resume:\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "full_prompt = few_shot_prompt | resume_optimizer_prompt\n",
    "\n",
    "resume_optimizer_chain = full_prompt | llm | JsonOutputParser()\n",
    "\n",
    "optimized_resume_json = resume_optimizer_chain.invoke({\"job_description\": job_description})\n",
    "\n",
    "print(optimized_resume_json)"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to FewShotChatMessagePromptTemplate is missing variables {'input'}.  Expected: ['input'] Received: ['job_description']\\nNote: if you intended {input} to be part of the string and not a variable, please escape it with double curly braces like: '{{input}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 32\u001B[0m\n\u001B[1;32m     28\u001B[0m full_prompt \u001B[38;5;241m=\u001B[39m few_shot_prompt \u001B[38;5;241m|\u001B[39m resume_optimizer_prompt\n\u001B[1;32m     30\u001B[0m resume_optimizer_chain \u001B[38;5;241m=\u001B[39m full_prompt \u001B[38;5;241m|\u001B[39m llm \u001B[38;5;241m|\u001B[39m JsonOutputParser()\n\u001B[0;32m---> 32\u001B[0m optimized_resume_json \u001B[38;5;241m=\u001B[39m \u001B[43mresume_optimizer_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mjob_description\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mjob_description\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(optimized_resume_json)\n",
      "File \u001B[0;32m~/anaconda3/envs/dstest/lib/python3.9/site-packages/langchain_core/runnables/base.py:3022\u001B[0m, in \u001B[0;36mRunnableSequence.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3020\u001B[0m context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, config)\n\u001B[1;32m   3021\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 3022\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3023\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3024\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(step\u001B[38;5;241m.\u001B[39minvoke, \u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m~/anaconda3/envs/dstest/lib/python3.9/site-packages/langchain_core/prompts/base.py:208\u001B[0m, in \u001B[0;36mBasePromptTemplate.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags:\n\u001B[1;32m    207\u001B[0m     config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags\n\u001B[0;32m--> 208\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_format_prompt_with_error_handling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    211\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrun_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprompt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserialized\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_serialized\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/dstest/lib/python3.9/site-packages/langchain_core/runnables/base.py:1927\u001B[0m, in \u001B[0;36mRunnable._call_with_config\u001B[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001B[0m\n\u001B[1;32m   1923\u001B[0m     context \u001B[38;5;241m=\u001B[39m copy_context()\n\u001B[1;32m   1924\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, child_config)\n\u001B[1;32m   1925\u001B[0m     output \u001B[38;5;241m=\u001B[39m cast(\n\u001B[1;32m   1926\u001B[0m         Output,\n\u001B[0;32m-> 1927\u001B[0m         \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1928\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1929\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1930\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1931\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1932\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1933\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1934\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1935\u001B[0m     )\n\u001B[1;32m   1936\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1937\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/anaconda3/envs/dstest/lib/python3.9/site-packages/langchain_core/runnables/config.py:396\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    395\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 396\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/dstest/lib/python3.9/site-packages/langchain_core/prompts/base.py:182\u001B[0m, in \u001B[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001B[0;34m(self, inner_input)\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_format_prompt_with_error_handling\u001B[39m(\u001B[38;5;28mself\u001B[39m, inner_input: \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PromptValue:\n\u001B[0;32m--> 182\u001B[0m     _inner_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43minner_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_prompt(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_inner_input)\n",
      "File \u001B[0;32m~/anaconda3/envs/dstest/lib/python3.9/site-packages/langchain_core/prompts/base.py:176\u001B[0m, in \u001B[0;36mBasePromptTemplate._validate_input\u001B[0;34m(self, inner_input)\u001B[0m\n\u001B[1;32m    170\u001B[0m     example_key \u001B[38;5;241m=\u001B[39m missing\u001B[38;5;241m.\u001B[39mpop()\n\u001B[1;32m    171\u001B[0m     msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    172\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mNote: if you intended \u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mexample_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m to be part of the string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    173\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m and not a variable, please escape it with double curly braces like: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    174\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mexample_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    175\u001B[0m     )\n\u001B[0;32m--> 176\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[1;32m    177\u001B[0m         create_message(message\u001B[38;5;241m=\u001B[39mmsg, error_code\u001B[38;5;241m=\u001B[39mErrorCode\u001B[38;5;241m.\u001B[39mINVALID_PROMPT_INPUT)\n\u001B[1;32m    178\u001B[0m     )\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m inner_input\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Input to FewShotChatMessagePromptTemplate is missing variables {'input'}.  Expected: ['input'] Received: ['job_description']\\nNote: if you intended {input} to be part of the string and not a variable, please escape it with double curly braces like: '{{input}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T22:21:33.276603Z",
     "start_time": "2025-04-17T20:44:56.387519Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"$schema\": \"https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/schema.json\",\n",
      "  \"basics\": {\n",
      "    \"name\": \"Richard Hendriks\",\n",
      "    \"label\": \"Data Scientist\",\n",
      "    \"image\": \"\",\n",
      "    \"email\": \"richard.hendriks@mail.com\",\n",
      "    \"phone\": \"(912) 555-4321\",\n",
      "    \"url\": \"http://richardhendricks.example.com\",\n",
      "    \"summary\": \"Results-driven data scientist with expertise in data analysis, machine learning, and statistical modeling. Proven track record of delivering insights that drive business growth.\",\n",
      "    \"location\": {\n",
      "      \"address\": \"2712 Broadway St\",\n",
      "      \"postalCode\": \"CA 94115\",\n",
      "      \"city\": \"San Francisco\",\n",
      "      \"countryCode\": \"US\",\n",
      "      \"region\": \"California\"\n",
      "    },\n",
      "    \"profiles\": [\n",
      "      {\n",
      "        \"network\": \"Twitter\",\n",
      "        \"username\": \"neutralthoughts\",\n",
      "        \"url\": \"https://www.twitter.com\"\n",
      "      },\n",
      "      {\n",
      "        \"network\": \"SoundCloud\",\n",
      "        \"username\": \"dandymusicnl\",\n",
      "        \"url\": \"https://soundcloud.example.com/dandym\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dstest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
