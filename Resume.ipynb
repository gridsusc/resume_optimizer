{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T20:54:23.408883Z",
     "start_time": "2025-04-05T20:54:16.441099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries with updated imports\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "# Define model ID and cache dir\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "cache_dir = \"./hf_models\"\n",
    "\n",
    "# Check device availability -this is for my macbook / you can use cuda if on windows\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device in [\"mps\", \"cuda\"] else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "# You can change this\n",
    "text_generation_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1,\n",
    "    return_full_text=False,  # This is important\n",
    "    clean_up_tokenization_spaces=True\n",
    ")\n",
    " \n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=text_generation_pipeline,\n",
    "    model_kwargs={\"return_full_text\": False}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T20:54:52.302840Z",
     "start_time": "2025-04-05T20:54:24.356615Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "targeted_resume_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert resume parser and JSON generator.\n",
    "    Given a professional's experience description, generate a structured JSON representation\n",
    "    of their work history. Focus only on the work experience section.\n",
    "\n",
    "    Output Format Instructions:\n",
    "    - Generate a JSON array of work experiences\n",
    "    - Each work experience should include:\n",
    "      * name: Company/Organization name\n",
    "      * position: Job title\n",
    "      * startDate: Start date in YYYY-MM-DD format\n",
    "      * endDate: End date in YYYY-MM-DD format (use current date if still employed)\n",
    "      * summary: Brief description of the role\n",
    "      * highlights: Key achievements or responsibilities\n",
    "\n",
    "    Ensure the JSON is valid and well-structured.\"\"\"),\n",
    "    (\"user\", \"Extract work experience from the following description:\\n{context}\")\n",
    "])\n",
    "\n",
    "work_experience_chain = targeted_resume_prompt | llm | json_parser\n",
    "\n",
    "input_text = \"\"\"\n",
    "John Smith worked at TechCorp as a Senior Software Engineer from 2018 to 2023.\n",
    "During his tenure, he led the development of a cloud-native microservices platform,\n",
    "reducing system latency by 40%. He implemented CI/CD pipelines and mentored junior\n",
    "developers. Prior to TechCorp, he was a Software Engineer at InnovateNow from 2015\n",
    "to 2018, where he developed machine learning algorithms for predictive analytics.\n",
    "\"\"\"\n",
    "\n",
    "work_experience = work_experience_chain.invoke({\"context\": input_text})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T20:20:29.322503Z",
     "start_time": "2025-04-05T20:20:28.000172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"name\": \"TechCorp\",\n",
      "    \"position\": \"Senior Software Engineer\",\n",
      "    \"startDate\": \"2018-01-01\",\n",
      "    \"endDate\": \"2023-12-31\",\n",
      "    \"summary\": \"Senior Software Engineer with expertise in cloud-native microservices and CI/CD pipelines.\",\n",
      "    \"highlights\": [\n",
      "      \"Reduced system latency by 40% through the implementation of CI/CD pipelines and mentoring junior developers.\",\n",
      "      \"Developed machine learning algorithms for predictive analytics at InnovateNow.\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"InnovateNow\",\n",
      "    \"position\": \"Software Engineer\",\n",
      "    \"startDate\": \"2015-01-01\",\n",
      "    \"endDate\": \"2018-12-31\",\n",
      "    \"summary\": \"Software Engineer with expertise in machine learning and predictive analytics.\",\n",
      "    \"highlights\": [\n",
      "      \"Developed machine learning algorithms for predictive analytics at InnovateNow.\",\n",
      "      \"Contributed to various projects as a Freelance Developer.\"\n",
      "    ]\n",
      "  },\n",
      "  {}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Print the generated work experience\n",
    "import json\n",
    "print(json.dumps(work_experience, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dstest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
